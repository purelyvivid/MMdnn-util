import tensorflow as tf

__weights_dict = dict()

is_train = False

def load_weights(weight_file):
    import numpy as np

    if weight_file == None:
        return

    try:
        weights_dict = np.load(weight_file).item()
    except:
        weights_dict = np.load(weight_file, encoding='bytes').item()

    return weights_dict


def KitModel(weight_file = None):
    global __weights_dict
    __weights_dict = load_weights(weight_file)

    input_1         = tf.placeholder(tf.float32,  shape = (None, 299, 299, 3), name = 'input_1')
    conv2d_1        = convolution(input_1, group=1, strides=[2, 2], padding='VALID', name='conv2d_1')
    batch_normalization_1 = batch_normalization(conv2d_1, variance_epsilon=0.0010000000475, name='batch_normalization_1')
    activation_1    = tf.nn.relu(batch_normalization_1, name = 'activation_1')
    conv2d_2        = convolution(activation_1, group=1, strides=[1, 1], padding='VALID', name='conv2d_2')
    batch_normalization_2 = batch_normalization(conv2d_2, variance_epsilon=0.0010000000475, name='batch_normalization_2')
    activation_2    = tf.nn.relu(batch_normalization_2, name = 'activation_2')
    conv2d_3        = convolution(activation_2, group=1, strides=[1, 1], padding='SAME', name='conv2d_3')
    batch_normalization_3 = batch_normalization(conv2d_3, variance_epsilon=0.0010000000475, name='batch_normalization_3')
    activation_3    = tf.nn.relu(batch_normalization_3, name = 'activation_3')
    max_pooling2d_1 = tf.nn.max_pool(activation_3, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='max_pooling2d_1')
    conv2d_4        = convolution(max_pooling2d_1, group=1, strides=[1, 1], padding='VALID', name='conv2d_4')
    batch_normalization_4 = batch_normalization(conv2d_4, variance_epsilon=0.0010000000475, name='batch_normalization_4')
    activation_4    = tf.nn.relu(batch_normalization_4, name = 'activation_4')
    conv2d_5        = convolution(activation_4, group=1, strides=[1, 1], padding='VALID', name='conv2d_5')
    batch_normalization_5 = batch_normalization(conv2d_5, variance_epsilon=0.0010000000475, name='batch_normalization_5')
    activation_5    = tf.nn.relu(batch_normalization_5, name = 'activation_5')
    max_pooling2d_2 = tf.nn.max_pool(activation_5, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='max_pooling2d_2')
    conv2d_9        = convolution(max_pooling2d_2, group=1, strides=[1, 1], padding='SAME', name='conv2d_9')
    conv2d_7        = convolution(max_pooling2d_2, group=1, strides=[1, 1], padding='SAME', name='conv2d_7')
    average_pooling2d_1 = tf.nn.avg_pool(max_pooling2d_2, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_1')
    conv2d_6        = convolution(max_pooling2d_2, group=1, strides=[1, 1], padding='SAME', name='conv2d_6')
    batch_normalization_9 = batch_normalization(conv2d_9, variance_epsilon=0.0010000000475, name='batch_normalization_9')
    batch_normalization_7 = batch_normalization(conv2d_7, variance_epsilon=0.0010000000475, name='batch_normalization_7')
    conv2d_12       = convolution(average_pooling2d_1, group=1, strides=[1, 1], padding='SAME', name='conv2d_12')
    batch_normalization_6 = batch_normalization(conv2d_6, variance_epsilon=0.0010000000475, name='batch_normalization_6')
    activation_9    = tf.nn.relu(batch_normalization_9, name = 'activation_9')
    activation_7    = tf.nn.relu(batch_normalization_7, name = 'activation_7')
    batch_normalization_12 = batch_normalization(conv2d_12, variance_epsilon=0.0010000000475, name='batch_normalization_12')
    activation_6    = tf.nn.relu(batch_normalization_6, name = 'activation_6')
    conv2d_10       = convolution(activation_9, group=1, strides=[1, 1], padding='SAME', name='conv2d_10')
    conv2d_8        = convolution(activation_7, group=1, strides=[1, 1], padding='SAME', name='conv2d_8')
    activation_12   = tf.nn.relu(batch_normalization_12, name = 'activation_12')
    batch_normalization_10 = batch_normalization(conv2d_10, variance_epsilon=0.0010000000475, name='batch_normalization_10')
    batch_normalization_8 = batch_normalization(conv2d_8, variance_epsilon=0.0010000000475, name='batch_normalization_8')
    activation_10   = tf.nn.relu(batch_normalization_10, name = 'activation_10')
    activation_8    = tf.nn.relu(batch_normalization_8, name = 'activation_8')
    conv2d_11       = convolution(activation_10, group=1, strides=[1, 1], padding='SAME', name='conv2d_11')
    batch_normalization_11 = batch_normalization(conv2d_11, variance_epsilon=0.0010000000475, name='batch_normalization_11')
    activation_11   = tf.nn.relu(batch_normalization_11, name = 'activation_11')
    mixed0          = tf.concat([activation_6, activation_8, activation_11, activation_12], 3, name = 'mixed0')
    conv2d_16       = convolution(mixed0, group=1, strides=[1, 1], padding='SAME', name='conv2d_16')
    conv2d_14       = convolution(mixed0, group=1, strides=[1, 1], padding='SAME', name='conv2d_14')
    average_pooling2d_2 = tf.nn.avg_pool(mixed0, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_2')
    conv2d_13       = convolution(mixed0, group=1, strides=[1, 1], padding='SAME', name='conv2d_13')
    batch_normalization_16 = batch_normalization(conv2d_16, variance_epsilon=0.0010000000475, name='batch_normalization_16')
    batch_normalization_14 = batch_normalization(conv2d_14, variance_epsilon=0.0010000000475, name='batch_normalization_14')
    conv2d_19       = convolution(average_pooling2d_2, group=1, strides=[1, 1], padding='SAME', name='conv2d_19')
    batch_normalization_13 = batch_normalization(conv2d_13, variance_epsilon=0.0010000000475, name='batch_normalization_13')
    activation_16   = tf.nn.relu(batch_normalization_16, name = 'activation_16')
    activation_14   = tf.nn.relu(batch_normalization_14, name = 'activation_14')
    batch_normalization_19 = batch_normalization(conv2d_19, variance_epsilon=0.0010000000475, name='batch_normalization_19')
    activation_13   = tf.nn.relu(batch_normalization_13, name = 'activation_13')
    conv2d_17       = convolution(activation_16, group=1, strides=[1, 1], padding='SAME', name='conv2d_17')
    conv2d_15       = convolution(activation_14, group=1, strides=[1, 1], padding='SAME', name='conv2d_15')
    activation_19   = tf.nn.relu(batch_normalization_19, name = 'activation_19')
    batch_normalization_17 = batch_normalization(conv2d_17, variance_epsilon=0.0010000000475, name='batch_normalization_17')
    batch_normalization_15 = batch_normalization(conv2d_15, variance_epsilon=0.0010000000475, name='batch_normalization_15')
    activation_17   = tf.nn.relu(batch_normalization_17, name = 'activation_17')
    activation_15   = tf.nn.relu(batch_normalization_15, name = 'activation_15')
    conv2d_18       = convolution(activation_17, group=1, strides=[1, 1], padding='SAME', name='conv2d_18')
    batch_normalization_18 = batch_normalization(conv2d_18, variance_epsilon=0.0010000000475, name='batch_normalization_18')
    activation_18   = tf.nn.relu(batch_normalization_18, name = 'activation_18')
    mixed1          = tf.concat([activation_13, activation_15, activation_18, activation_19], 3, name = 'mixed1')
    conv2d_23       = convolution(mixed1, group=1, strides=[1, 1], padding='SAME', name='conv2d_23')
    conv2d_21       = convolution(mixed1, group=1, strides=[1, 1], padding='SAME', name='conv2d_21')
    average_pooling2d_3 = tf.nn.avg_pool(mixed1, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_3')
    conv2d_20       = convolution(mixed1, group=1, strides=[1, 1], padding='SAME', name='conv2d_20')
    batch_normalization_23 = batch_normalization(conv2d_23, variance_epsilon=0.0010000000475, name='batch_normalization_23')
    batch_normalization_21 = batch_normalization(conv2d_21, variance_epsilon=0.0010000000475, name='batch_normalization_21')
    conv2d_26       = convolution(average_pooling2d_3, group=1, strides=[1, 1], padding='SAME', name='conv2d_26')
    batch_normalization_20 = batch_normalization(conv2d_20, variance_epsilon=0.0010000000475, name='batch_normalization_20')
    activation_23   = tf.nn.relu(batch_normalization_23, name = 'activation_23')
    activation_21   = tf.nn.relu(batch_normalization_21, name = 'activation_21')
    batch_normalization_26 = batch_normalization(conv2d_26, variance_epsilon=0.0010000000475, name='batch_normalization_26')
    activation_20   = tf.nn.relu(batch_normalization_20, name = 'activation_20')
    conv2d_24       = convolution(activation_23, group=1, strides=[1, 1], padding='SAME', name='conv2d_24')
    conv2d_22       = convolution(activation_21, group=1, strides=[1, 1], padding='SAME', name='conv2d_22')
    activation_26   = tf.nn.relu(batch_normalization_26, name = 'activation_26')
    batch_normalization_24 = batch_normalization(conv2d_24, variance_epsilon=0.0010000000475, name='batch_normalization_24')
    batch_normalization_22 = batch_normalization(conv2d_22, variance_epsilon=0.0010000000475, name='batch_normalization_22')
    activation_24   = tf.nn.relu(batch_normalization_24, name = 'activation_24')
    activation_22   = tf.nn.relu(batch_normalization_22, name = 'activation_22')
    conv2d_25       = convolution(activation_24, group=1, strides=[1, 1], padding='SAME', name='conv2d_25')
    batch_normalization_25 = batch_normalization(conv2d_25, variance_epsilon=0.0010000000475, name='batch_normalization_25')
    activation_25   = tf.nn.relu(batch_normalization_25, name = 'activation_25')
    mixed2          = tf.concat([activation_20, activation_22, activation_25, activation_26], 3, name = 'mixed2')
    conv2d_28       = convolution(mixed2, group=1, strides=[1, 1], padding='SAME', name='conv2d_28')
    conv2d_27       = convolution(mixed2, group=1, strides=[2, 2], padding='VALID', name='conv2d_27')
    max_pooling2d_3 = tf.nn.max_pool(mixed2, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='max_pooling2d_3')
    batch_normalization_28 = batch_normalization(conv2d_28, variance_epsilon=0.0010000000475, name='batch_normalization_28')
    batch_normalization_27 = batch_normalization(conv2d_27, variance_epsilon=0.0010000000475, name='batch_normalization_27')
    activation_28   = tf.nn.relu(batch_normalization_28, name = 'activation_28')
    activation_27   = tf.nn.relu(batch_normalization_27, name = 'activation_27')
    conv2d_29       = convolution(activation_28, group=1, strides=[1, 1], padding='SAME', name='conv2d_29')
    batch_normalization_29 = batch_normalization(conv2d_29, variance_epsilon=0.0010000000475, name='batch_normalization_29')
    activation_29   = tf.nn.relu(batch_normalization_29, name = 'activation_29')
    conv2d_30       = convolution(activation_29, group=1, strides=[2, 2], padding='VALID', name='conv2d_30')
    batch_normalization_30 = batch_normalization(conv2d_30, variance_epsilon=0.0010000000475, name='batch_normalization_30')
    activation_30   = tf.nn.relu(batch_normalization_30, name = 'activation_30')
    mixed3          = tf.concat([activation_27, activation_30, max_pooling2d_3], 3, name = 'mixed3')
    conv2d_35       = convolution(mixed3, group=1, strides=[1, 1], padding='SAME', name='conv2d_35')
    conv2d_32       = convolution(mixed3, group=1, strides=[1, 1], padding='SAME', name='conv2d_32')
    average_pooling2d_4 = tf.nn.avg_pool(mixed3, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_4')
    conv2d_31       = convolution(mixed3, group=1, strides=[1, 1], padding='SAME', name='conv2d_31')
    batch_normalization_35 = batch_normalization(conv2d_35, variance_epsilon=0.0010000000475, name='batch_normalization_35')
    batch_normalization_32 = batch_normalization(conv2d_32, variance_epsilon=0.0010000000475, name='batch_normalization_32')
    conv2d_40       = convolution(average_pooling2d_4, group=1, strides=[1, 1], padding='SAME', name='conv2d_40')
    batch_normalization_31 = batch_normalization(conv2d_31, variance_epsilon=0.0010000000475, name='batch_normalization_31')
    activation_35   = tf.nn.relu(batch_normalization_35, name = 'activation_35')
    activation_32   = tf.nn.relu(batch_normalization_32, name = 'activation_32')
    batch_normalization_40 = batch_normalization(conv2d_40, variance_epsilon=0.0010000000475, name='batch_normalization_40')
    activation_31   = tf.nn.relu(batch_normalization_31, name = 'activation_31')
    conv2d_36       = convolution(activation_35, group=1, strides=[1, 1], padding='SAME', name='conv2d_36')
    conv2d_33       = convolution(activation_32, group=1, strides=[1, 1], padding='SAME', name='conv2d_33')
    activation_40   = tf.nn.relu(batch_normalization_40, name = 'activation_40')
    batch_normalization_36 = batch_normalization(conv2d_36, variance_epsilon=0.0010000000475, name='batch_normalization_36')
    batch_normalization_33 = batch_normalization(conv2d_33, variance_epsilon=0.0010000000475, name='batch_normalization_33')
    activation_36   = tf.nn.relu(batch_normalization_36, name = 'activation_36')
    activation_33   = tf.nn.relu(batch_normalization_33, name = 'activation_33')
    conv2d_37       = convolution(activation_36, group=1, strides=[1, 1], padding='SAME', name='conv2d_37')
    conv2d_34       = convolution(activation_33, group=1, strides=[1, 1], padding='SAME', name='conv2d_34')
    batch_normalization_37 = batch_normalization(conv2d_37, variance_epsilon=0.0010000000475, name='batch_normalization_37')
    batch_normalization_34 = batch_normalization(conv2d_34, variance_epsilon=0.0010000000475, name='batch_normalization_34')
    activation_37   = tf.nn.relu(batch_normalization_37, name = 'activation_37')
    activation_34   = tf.nn.relu(batch_normalization_34, name = 'activation_34')
    conv2d_38       = convolution(activation_37, group=1, strides=[1, 1], padding='SAME', name='conv2d_38')
    batch_normalization_38 = batch_normalization(conv2d_38, variance_epsilon=0.0010000000475, name='batch_normalization_38')
    activation_38   = tf.nn.relu(batch_normalization_38, name = 'activation_38')
    conv2d_39       = convolution(activation_38, group=1, strides=[1, 1], padding='SAME', name='conv2d_39')
    batch_normalization_39 = batch_normalization(conv2d_39, variance_epsilon=0.0010000000475, name='batch_normalization_39')
    activation_39   = tf.nn.relu(batch_normalization_39, name = 'activation_39')
    mixed4          = tf.concat([activation_31, activation_34, activation_39, activation_40], 3, name = 'mixed4')
    conv2d_45       = convolution(mixed4, group=1, strides=[1, 1], padding='SAME', name='conv2d_45')
    conv2d_42       = convolution(mixed4, group=1, strides=[1, 1], padding='SAME', name='conv2d_42')
    average_pooling2d_5 = tf.nn.avg_pool(mixed4, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_5')
    conv2d_41       = convolution(mixed4, group=1, strides=[1, 1], padding='SAME', name='conv2d_41')
    batch_normalization_45 = batch_normalization(conv2d_45, variance_epsilon=0.0010000000475, name='batch_normalization_45')
    batch_normalization_42 = batch_normalization(conv2d_42, variance_epsilon=0.0010000000475, name='batch_normalization_42')
    conv2d_50       = convolution(average_pooling2d_5, group=1, strides=[1, 1], padding='SAME', name='conv2d_50')
    batch_normalization_41 = batch_normalization(conv2d_41, variance_epsilon=0.0010000000475, name='batch_normalization_41')
    activation_45   = tf.nn.relu(batch_normalization_45, name = 'activation_45')
    activation_42   = tf.nn.relu(batch_normalization_42, name = 'activation_42')
    batch_normalization_50 = batch_normalization(conv2d_50, variance_epsilon=0.0010000000475, name='batch_normalization_50')
    activation_41   = tf.nn.relu(batch_normalization_41, name = 'activation_41')
    conv2d_46       = convolution(activation_45, group=1, strides=[1, 1], padding='SAME', name='conv2d_46')
    conv2d_43       = convolution(activation_42, group=1, strides=[1, 1], padding='SAME', name='conv2d_43')
    activation_50   = tf.nn.relu(batch_normalization_50, name = 'activation_50')
    batch_normalization_46 = batch_normalization(conv2d_46, variance_epsilon=0.0010000000475, name='batch_normalization_46')
    batch_normalization_43 = batch_normalization(conv2d_43, variance_epsilon=0.0010000000475, name='batch_normalization_43')
    activation_46   = tf.nn.relu(batch_normalization_46, name = 'activation_46')
    activation_43   = tf.nn.relu(batch_normalization_43, name = 'activation_43')
    conv2d_47       = convolution(activation_46, group=1, strides=[1, 1], padding='SAME', name='conv2d_47')
    conv2d_44       = convolution(activation_43, group=1, strides=[1, 1], padding='SAME', name='conv2d_44')
    batch_normalization_47 = batch_normalization(conv2d_47, variance_epsilon=0.0010000000475, name='batch_normalization_47')
    batch_normalization_44 = batch_normalization(conv2d_44, variance_epsilon=0.0010000000475, name='batch_normalization_44')
    activation_47   = tf.nn.relu(batch_normalization_47, name = 'activation_47')
    activation_44   = tf.nn.relu(batch_normalization_44, name = 'activation_44')
    conv2d_48       = convolution(activation_47, group=1, strides=[1, 1], padding='SAME', name='conv2d_48')
    batch_normalization_48 = batch_normalization(conv2d_48, variance_epsilon=0.0010000000475, name='batch_normalization_48')
    activation_48   = tf.nn.relu(batch_normalization_48, name = 'activation_48')
    conv2d_49       = convolution(activation_48, group=1, strides=[1, 1], padding='SAME', name='conv2d_49')
    batch_normalization_49 = batch_normalization(conv2d_49, variance_epsilon=0.0010000000475, name='batch_normalization_49')
    activation_49   = tf.nn.relu(batch_normalization_49, name = 'activation_49')
    mixed5          = tf.concat([activation_41, activation_44, activation_49, activation_50], 3, name = 'mixed5')
    conv2d_55       = convolution(mixed5, group=1, strides=[1, 1], padding='SAME', name='conv2d_55')
    conv2d_52       = convolution(mixed5, group=1, strides=[1, 1], padding='SAME', name='conv2d_52')
    average_pooling2d_6 = tf.nn.avg_pool(mixed5, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_6')
    conv2d_51       = convolution(mixed5, group=1, strides=[1, 1], padding='SAME', name='conv2d_51')
    batch_normalization_55 = batch_normalization(conv2d_55, variance_epsilon=0.0010000000475, name='batch_normalization_55')
    batch_normalization_52 = batch_normalization(conv2d_52, variance_epsilon=0.0010000000475, name='batch_normalization_52')
    conv2d_60       = convolution(average_pooling2d_6, group=1, strides=[1, 1], padding='SAME', name='conv2d_60')
    batch_normalization_51 = batch_normalization(conv2d_51, variance_epsilon=0.0010000000475, name='batch_normalization_51')
    activation_55   = tf.nn.relu(batch_normalization_55, name = 'activation_55')
    activation_52   = tf.nn.relu(batch_normalization_52, name = 'activation_52')
    batch_normalization_60 = batch_normalization(conv2d_60, variance_epsilon=0.0010000000475, name='batch_normalization_60')
    activation_51   = tf.nn.relu(batch_normalization_51, name = 'activation_51')
    conv2d_56       = convolution(activation_55, group=1, strides=[1, 1], padding='SAME', name='conv2d_56')
    conv2d_53       = convolution(activation_52, group=1, strides=[1, 1], padding='SAME', name='conv2d_53')
    activation_60   = tf.nn.relu(batch_normalization_60, name = 'activation_60')
    batch_normalization_56 = batch_normalization(conv2d_56, variance_epsilon=0.0010000000475, name='batch_normalization_56')
    batch_normalization_53 = batch_normalization(conv2d_53, variance_epsilon=0.0010000000475, name='batch_normalization_53')
    activation_56   = tf.nn.relu(batch_normalization_56, name = 'activation_56')
    activation_53   = tf.nn.relu(batch_normalization_53, name = 'activation_53')
    conv2d_57       = convolution(activation_56, group=1, strides=[1, 1], padding='SAME', name='conv2d_57')
    conv2d_54       = convolution(activation_53, group=1, strides=[1, 1], padding='SAME', name='conv2d_54')
    batch_normalization_57 = batch_normalization(conv2d_57, variance_epsilon=0.0010000000475, name='batch_normalization_57')
    batch_normalization_54 = batch_normalization(conv2d_54, variance_epsilon=0.0010000000475, name='batch_normalization_54')
    activation_57   = tf.nn.relu(batch_normalization_57, name = 'activation_57')
    activation_54   = tf.nn.relu(batch_normalization_54, name = 'activation_54')
    conv2d_58       = convolution(activation_57, group=1, strides=[1, 1], padding='SAME', name='conv2d_58')
    batch_normalization_58 = batch_normalization(conv2d_58, variance_epsilon=0.0010000000475, name='batch_normalization_58')
    activation_58   = tf.nn.relu(batch_normalization_58, name = 'activation_58')
    conv2d_59       = convolution(activation_58, group=1, strides=[1, 1], padding='SAME', name='conv2d_59')
    batch_normalization_59 = batch_normalization(conv2d_59, variance_epsilon=0.0010000000475, name='batch_normalization_59')
    activation_59   = tf.nn.relu(batch_normalization_59, name = 'activation_59')
    mixed6          = tf.concat([activation_51, activation_54, activation_59, activation_60], 3, name = 'mixed6')
    conv2d_65       = convolution(mixed6, group=1, strides=[1, 1], padding='SAME', name='conv2d_65')
    conv2d_62       = convolution(mixed6, group=1, strides=[1, 1], padding='SAME', name='conv2d_62')
    average_pooling2d_7 = tf.nn.avg_pool(mixed6, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_7')
    conv2d_61       = convolution(mixed6, group=1, strides=[1, 1], padding='SAME', name='conv2d_61')
    batch_normalization_65 = batch_normalization(conv2d_65, variance_epsilon=0.0010000000475, name='batch_normalization_65')
    batch_normalization_62 = batch_normalization(conv2d_62, variance_epsilon=0.0010000000475, name='batch_normalization_62')
    conv2d_70       = convolution(average_pooling2d_7, group=1, strides=[1, 1], padding='SAME', name='conv2d_70')
    batch_normalization_61 = batch_normalization(conv2d_61, variance_epsilon=0.0010000000475, name='batch_normalization_61')
    activation_65   = tf.nn.relu(batch_normalization_65, name = 'activation_65')
    activation_62   = tf.nn.relu(batch_normalization_62, name = 'activation_62')
    batch_normalization_70 = batch_normalization(conv2d_70, variance_epsilon=0.0010000000475, name='batch_normalization_70')
    activation_61   = tf.nn.relu(batch_normalization_61, name = 'activation_61')
    conv2d_66       = convolution(activation_65, group=1, strides=[1, 1], padding='SAME', name='conv2d_66')
    conv2d_63       = convolution(activation_62, group=1, strides=[1, 1], padding='SAME', name='conv2d_63')
    activation_70   = tf.nn.relu(batch_normalization_70, name = 'activation_70')
    batch_normalization_66 = batch_normalization(conv2d_66, variance_epsilon=0.0010000000475, name='batch_normalization_66')
    batch_normalization_63 = batch_normalization(conv2d_63, variance_epsilon=0.0010000000475, name='batch_normalization_63')
    activation_66   = tf.nn.relu(batch_normalization_66, name = 'activation_66')
    activation_63   = tf.nn.relu(batch_normalization_63, name = 'activation_63')
    conv2d_67       = convolution(activation_66, group=1, strides=[1, 1], padding='SAME', name='conv2d_67')
    conv2d_64       = convolution(activation_63, group=1, strides=[1, 1], padding='SAME', name='conv2d_64')
    batch_normalization_67 = batch_normalization(conv2d_67, variance_epsilon=0.0010000000475, name='batch_normalization_67')
    batch_normalization_64 = batch_normalization(conv2d_64, variance_epsilon=0.0010000000475, name='batch_normalization_64')
    activation_67   = tf.nn.relu(batch_normalization_67, name = 'activation_67')
    activation_64   = tf.nn.relu(batch_normalization_64, name = 'activation_64')
    conv2d_68       = convolution(activation_67, group=1, strides=[1, 1], padding='SAME', name='conv2d_68')
    batch_normalization_68 = batch_normalization(conv2d_68, variance_epsilon=0.0010000000475, name='batch_normalization_68')
    activation_68   = tf.nn.relu(batch_normalization_68, name = 'activation_68')
    conv2d_69       = convolution(activation_68, group=1, strides=[1, 1], padding='SAME', name='conv2d_69')
    batch_normalization_69 = batch_normalization(conv2d_69, variance_epsilon=0.0010000000475, name='batch_normalization_69')
    activation_69   = tf.nn.relu(batch_normalization_69, name = 'activation_69')
    mixed7          = tf.concat([activation_61, activation_64, activation_69, activation_70], 3, name = 'mixed7')
    conv2d_73       = convolution(mixed7, group=1, strides=[1, 1], padding='SAME', name='conv2d_73')
    conv2d_71       = convolution(mixed7, group=1, strides=[1, 1], padding='SAME', name='conv2d_71')
    max_pooling2d_4 = tf.nn.max_pool(mixed7, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='max_pooling2d_4')
    batch_normalization_73 = batch_normalization(conv2d_73, variance_epsilon=0.0010000000475, name='batch_normalization_73')
    batch_normalization_71 = batch_normalization(conv2d_71, variance_epsilon=0.0010000000475, name='batch_normalization_71')
    activation_73   = tf.nn.relu(batch_normalization_73, name = 'activation_73')
    activation_71   = tf.nn.relu(batch_normalization_71, name = 'activation_71')
    conv2d_74       = convolution(activation_73, group=1, strides=[1, 1], padding='SAME', name='conv2d_74')
    conv2d_72       = convolution(activation_71, group=1, strides=[2, 2], padding='VALID', name='conv2d_72')
    batch_normalization_74 = batch_normalization(conv2d_74, variance_epsilon=0.0010000000475, name='batch_normalization_74')
    batch_normalization_72 = batch_normalization(conv2d_72, variance_epsilon=0.0010000000475, name='batch_normalization_72')
    activation_74   = tf.nn.relu(batch_normalization_74, name = 'activation_74')
    activation_72   = tf.nn.relu(batch_normalization_72, name = 'activation_72')
    conv2d_75       = convolution(activation_74, group=1, strides=[1, 1], padding='SAME', name='conv2d_75')
    batch_normalization_75 = batch_normalization(conv2d_75, variance_epsilon=0.0010000000475, name='batch_normalization_75')
    activation_75   = tf.nn.relu(batch_normalization_75, name = 'activation_75')
    conv2d_76       = convolution(activation_75, group=1, strides=[2, 2], padding='VALID', name='conv2d_76')
    batch_normalization_76 = batch_normalization(conv2d_76, variance_epsilon=0.0010000000475, name='batch_normalization_76')
    activation_76   = tf.nn.relu(batch_normalization_76, name = 'activation_76')
    mixed8          = tf.concat([activation_72, activation_76, max_pooling2d_4], 3, name = 'mixed8')
    conv2d_81       = convolution(mixed8, group=1, strides=[1, 1], padding='SAME', name='conv2d_81')
    conv2d_78       = convolution(mixed8, group=1, strides=[1, 1], padding='SAME', name='conv2d_78')
    average_pooling2d_8 = tf.nn.avg_pool(mixed8, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_8')
    conv2d_77       = convolution(mixed8, group=1, strides=[1, 1], padding='SAME', name='conv2d_77')
    batch_normalization_81 = batch_normalization(conv2d_81, variance_epsilon=0.0010000000475, name='batch_normalization_81')
    batch_normalization_78 = batch_normalization(conv2d_78, variance_epsilon=0.0010000000475, name='batch_normalization_78')
    conv2d_85       = convolution(average_pooling2d_8, group=1, strides=[1, 1], padding='SAME', name='conv2d_85')
    batch_normalization_77 = batch_normalization(conv2d_77, variance_epsilon=0.0010000000475, name='batch_normalization_77')
    activation_81   = tf.nn.relu(batch_normalization_81, name = 'activation_81')
    activation_78   = tf.nn.relu(batch_normalization_78, name = 'activation_78')
    batch_normalization_85 = batch_normalization(conv2d_85, variance_epsilon=0.0010000000475, name='batch_normalization_85')
    activation_77   = tf.nn.relu(batch_normalization_77, name = 'activation_77')
    conv2d_82       = convolution(activation_81, group=1, strides=[1, 1], padding='SAME', name='conv2d_82')
    conv2d_79       = convolution(activation_78, group=1, strides=[1, 1], padding='SAME', name='conv2d_79')
    conv2d_80       = convolution(activation_78, group=1, strides=[1, 1], padding='SAME', name='conv2d_80')
    activation_85   = tf.nn.relu(batch_normalization_85, name = 'activation_85')
    batch_normalization_82 = batch_normalization(conv2d_82, variance_epsilon=0.0010000000475, name='batch_normalization_82')
    batch_normalization_79 = batch_normalization(conv2d_79, variance_epsilon=0.0010000000475, name='batch_normalization_79')
    batch_normalization_80 = batch_normalization(conv2d_80, variance_epsilon=0.0010000000475, name='batch_normalization_80')
    activation_82   = tf.nn.relu(batch_normalization_82, name = 'activation_82')
    activation_79   = tf.nn.relu(batch_normalization_79, name = 'activation_79')
    activation_80   = tf.nn.relu(batch_normalization_80, name = 'activation_80')
    conv2d_83       = convolution(activation_82, group=1, strides=[1, 1], padding='SAME', name='conv2d_83')
    conv2d_84       = convolution(activation_82, group=1, strides=[1, 1], padding='SAME', name='conv2d_84')
    mixed9_0        = tf.concat([activation_79, activation_80], 3, name = 'mixed9_0')
    batch_normalization_83 = batch_normalization(conv2d_83, variance_epsilon=0.0010000000475, name='batch_normalization_83')
    batch_normalization_84 = batch_normalization(conv2d_84, variance_epsilon=0.0010000000475, name='batch_normalization_84')
    activation_83   = tf.nn.relu(batch_normalization_83, name = 'activation_83')
    activation_84   = tf.nn.relu(batch_normalization_84, name = 'activation_84')
    concatenate_1   = tf.concat([activation_83, activation_84], 3, name = 'concatenate_1')
    mixed9          = tf.concat([activation_77, mixed9_0, concatenate_1, activation_85], 3, name = 'mixed9')
    conv2d_90       = convolution(mixed9, group=1, strides=[1, 1], padding='SAME', name='conv2d_90')
    conv2d_87       = convolution(mixed9, group=1, strides=[1, 1], padding='SAME', name='conv2d_87')
    average_pooling2d_9 = tf.nn.avg_pool(mixed9, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='average_pooling2d_9')
    conv2d_86       = convolution(mixed9, group=1, strides=[1, 1], padding='SAME', name='conv2d_86')
    batch_normalization_90 = batch_normalization(conv2d_90, variance_epsilon=0.0010000000475, name='batch_normalization_90')
    batch_normalization_87 = batch_normalization(conv2d_87, variance_epsilon=0.0010000000475, name='batch_normalization_87')
    conv2d_94       = convolution(average_pooling2d_9, group=1, strides=[1, 1], padding='SAME', name='conv2d_94')
    batch_normalization_86 = batch_normalization(conv2d_86, variance_epsilon=0.0010000000475, name='batch_normalization_86')
    activation_90   = tf.nn.relu(batch_normalization_90, name = 'activation_90')
    activation_87   = tf.nn.relu(batch_normalization_87, name = 'activation_87')
    batch_normalization_94 = batch_normalization(conv2d_94, variance_epsilon=0.0010000000475, name='batch_normalization_94')
    activation_86   = tf.nn.relu(batch_normalization_86, name = 'activation_86')
    conv2d_91       = convolution(activation_90, group=1, strides=[1, 1], padding='SAME', name='conv2d_91')
    conv2d_88       = convolution(activation_87, group=1, strides=[1, 1], padding='SAME', name='conv2d_88')
    conv2d_89       = convolution(activation_87, group=1, strides=[1, 1], padding='SAME', name='conv2d_89')
    activation_94   = tf.nn.relu(batch_normalization_94, name = 'activation_94')
    batch_normalization_91 = batch_normalization(conv2d_91, variance_epsilon=0.0010000000475, name='batch_normalization_91')
    batch_normalization_88 = batch_normalization(conv2d_88, variance_epsilon=0.0010000000475, name='batch_normalization_88')
    batch_normalization_89 = batch_normalization(conv2d_89, variance_epsilon=0.0010000000475, name='batch_normalization_89')
    activation_91   = tf.nn.relu(batch_normalization_91, name = 'activation_91')
    activation_88   = tf.nn.relu(batch_normalization_88, name = 'activation_88')
    activation_89   = tf.nn.relu(batch_normalization_89, name = 'activation_89')
    conv2d_92       = convolution(activation_91, group=1, strides=[1, 1], padding='SAME', name='conv2d_92')
    conv2d_93       = convolution(activation_91, group=1, strides=[1, 1], padding='SAME', name='conv2d_93')
    mixed9_1        = tf.concat([activation_88, activation_89], 3, name = 'mixed9_1')
    batch_normalization_92 = batch_normalization(conv2d_92, variance_epsilon=0.0010000000475, name='batch_normalization_92')
    batch_normalization_93 = batch_normalization(conv2d_93, variance_epsilon=0.0010000000475, name='batch_normalization_93')
    activation_92   = tf.nn.relu(batch_normalization_92, name = 'activation_92')
    activation_93   = tf.nn.relu(batch_normalization_93, name = 'activation_93')
    concatenate_2   = tf.concat([activation_92, activation_93], 3, name = 'concatenate_2')
    mixed10         = tf.concat([activation_86, mixed9_1, concatenate_2, activation_94], 3, name = 'mixed10')
    avg_pool        = tf.nn.avg_pool(mixed10, [1] + mixed10.get_shape().as_list()[1:-1] + [1], strides = [1] * 4, padding = 'VALID', name = 'avg_pool')
    avg_pool_flatten = tf.contrib.layers.flatten(avg_pool)
    predictions     = tf.layers.dense(avg_pool_flatten, 1000, kernel_initializer = tf.constant_initializer(__weights_dict['predictions']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['predictions']['bias']), use_bias = True)
    predictions_activation = tf.nn.softmax(predictions, name = 'predictions_activation')
    return input_1, predictions_activation


def batch_normalization(input, name, **kwargs):
    mean = tf.Variable(__weights_dict[name]['mean'], name = name + "_mean", trainable = is_train)
    variance = tf.Variable(__weights_dict[name]['var'], name = name + "_var", trainable = is_train)
    offset = tf.Variable(__weights_dict[name]['bias'], name = name + "_bias", trainable = is_train) if 'bias' in __weights_dict[name] else None
    scale = tf.Variable(__weights_dict[name]['scale'], name = name + "_scale", trainable = is_train) if 'scale' in __weights_dict[name] else None
    return tf.nn.batch_normalization(input, mean, variance, offset, scale, name = name, **kwargs)


def convolution(input, name, group, **kwargs):
    w = tf.Variable(__weights_dict[name]['weights'], trainable=is_train, name=name + "_weight")
    if group == 1:
        layer = tf.nn.convolution(input, w, **kwargs)
    else:
        weight_groups = tf.split(w, num_or_size_splits=group, axis=-1)
        xs = tf.split(input, num_or_size_splits=group, axis=-1)
        convolved = [tf.nn.convolution(x, weight, **kwargs) for
                    (x, weight) in zip(xs, weight_groups)]
        layer = tf.concat(convolved, axis=-1)

    if 'bias' in __weights_dict[name]:
        b = tf.Variable(__weights_dict[name]['bias'], trainable=is_train, name=name + "_bias")
        layer = layer + b
    return layer
